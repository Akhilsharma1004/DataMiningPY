{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "566b815e",
   "metadata": {},
   "source": [
    "# Example Code\n",
    "\n",
    "Make your way through this notebook and make sure you understand what the code is doing. You can use this understanding to complete your assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62342e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages we'll use in this notebook\n",
    "import pandas as pd\n",
    "import collections\n",
    "from ast import literal_eval\n",
    "from itertools import permutations\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a518fb6",
   "metadata": {},
   "source": [
    "### Read in the example data\n",
    "\n",
    "Because our data is stored in csv, pandas will read our data values as strings.\n",
    "Instead, we can specify we want our Colours column to be evaluated literally since we already know it is a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e9e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into a DataFrame\n",
    "df = pd.read_csv('data/example_data.csv', converters={'Colours': literal_eval}) \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffe413",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) # dataframe shape \n",
    "print(df.shape[0]) # number of rows \n",
    "print(df.shape[1]) # number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc74473f",
   "metadata": {},
   "source": [
    "Drop unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126dba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbcd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted column\n",
    "df.drop('Price', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e589c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change pandas default index to the transaction ID\n",
    "df.set_index('Transaction_ID', inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad5ff6c",
   "metadata": {},
   "source": [
    "#### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e28132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a4e5cb",
   "metadata": {},
   "source": [
    "### Format Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f461c",
   "metadata": {},
   "source": [
    "We need to re-format the data so we can (later) create our binary indicator matrix (one-hot encoding, see more: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/)\n",
    "\n",
    "First, let's split out that column of lists and put each item in its own column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f349171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length of the longest list so we know how many columns to create\n",
    "max_len = df.Colours.str.len().max()\n",
    "print(max_len)\n",
    "\n",
    "# generate column names\n",
    "cols = [i for i in range(0,4)]\n",
    "print(cols)\n",
    "\n",
    "# create a new dataframe with split out columns\n",
    "df_split = pd.DataFrame(df[\"Colours\"].tolist(), columns=[0,1,2,3])#.fillna(value=np.nan)\n",
    "df_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ed6af",
   "metadata": {},
   "source": [
    "Now that we have our data in a structure we're happy with, let's do some exploring with our association rules in mind. \n",
    "\n",
    "Let's create a list of lists, where each row in the df_split is a list in our list, i.e. our list will contain all transactions, each of which is also a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate an empty list\n",
    "transactions = []\n",
    "# iterate through each row and column to create the list\n",
    "for i in range(0, len(df_split)): \n",
    "    transactions.append([str(df_split.values[i,j]) for j in range(0, len(df_split.columns))])\n",
    "\n",
    "# look at first two lists\n",
    "transactions[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275566d4",
   "metadata": {},
   "source": [
    "Now let's create one master list by flattening our list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the list of lists to get a list containint all items in the dataset\n",
    "flattened = [item for transaction in transactions for item in transaction]\n",
    "print(len(flattened))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7ff7f",
   "metadata": {},
   "source": [
    "Let's view only the unique items in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of unique items from the flattened list\n",
    "# use the set() method because a set by definition contains only unique items\n",
    "items = list(set(flattened))\n",
    "\n",
    "# print the count of unique items which is the length of the list\n",
    "print('# of items:',len(items))\n",
    "\n",
    "# sort items alphabeitcally\n",
    "items.sort() \n",
    "print(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86209f07",
   "metadata": {},
   "source": [
    "Let's drop the None value from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428f5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: you can replace any string here, e.g. \"nan\" or punctuation\n",
    "if 'None' in flattened: flattened.remove('None')\n",
    "len(flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410a473",
   "metadata": {},
   "source": [
    "Let's count how many rules we could generate for this dataset if we looked at all combinations of 3-itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll call these combinations rules and use the permutations method we imported \n",
    "# we pass the items list to the permutations method \n",
    "# and set the itemset size limit to 3\n",
    "rules = list(permutations(items, 3))\n",
    "print('# of rules:',len(rules))\n",
    "print(rules[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad1583e",
   "metadata": {},
   "source": [
    "We can look at the frequency of each item to see how popular it is in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ec0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use our list that contains all items and use the Counter method\n",
    "item_freq = collections.Counter(flattened)\n",
    "item_freq.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f03b9",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "we'll use TransactionEncoder to convert data to one hot encoding (our binary incident matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an encoder object that is fit to our list of lists we created earlier\n",
    "encoder = TransactionEncoder().fit(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934dd26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoded array\n",
    "onehot = encoder.transform(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2630b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the ecoded values and the item names as columns\n",
    "# We need to drop the \"None\" value or it will become its own columng\n",
    "df_onehot = pd.DataFrame(onehot, columns=encoder.columns_).drop('None', axis=1)\n",
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2671c966",
   "metadata": {},
   "source": [
    "Now we have our data encoded and we're ready to apply the apriori algorithm. Note how the values in our df are TRUE and FALSE, where previously we've seen 0s and 1s. Conceptually, they are the same thing.\n",
    "\n",
    "The mlxtend apriori methd accepts TRUE/FALSE or 1/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fc3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate frequent itemsets with a minimum support of 20%\n",
    "df_itemsets = apriori(df_onehot, min_support=0.2, use_colnames=True)\n",
    "\n",
    "# itemsets_df is a DataFrame, let's see how many itemsets it contains\n",
    "df_itemsets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_itemsets.sort_values(by=['support'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2648ced6",
   "metadata": {},
   "source": [
    "Now we can use the association_rules() method to generate a dataframe with out rules and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum threshold of 50%\n",
    "rules_df = association_rules(df_itemsets, metric='confidence', min_threshold=0.5)\n",
    "rules_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f41445c",
   "metadata": {},
   "source": [
    "Now let's have a look at the 5 strongest rules, sorted by lift, and ignoring some of the fields we're not interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets just have a look at our strongest rules\n",
    "print(rules_df.sort_values(by=['lift'], ascending=False)\n",
    "      .drop(columns=['antecedent support', 'consequent support', 'conviction'])\n",
    "      .head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6131bcc",
   "metadata": {},
   "source": [
    "#### Rule {Green}⇒{White, Red}\n",
    "\n",
    "If green is purchased, then white and red will also be purchased with confidence of 95%. This rule has a lift ratio of 2.27. \n",
    "\n",
    "This rule has support of 0.21 which means 21% of transactions are impacted. The lift ratio indicates this not occuring by chance and the confidence is high, thus it seems like this rule could be useful for a marketing campaign or for cross-selling on the website.\n",
    "\n",
    "{Orange}⇒{White} may also be promising with almost as much support (20%), the same high confidence (95%), and a lift of 1.32 that suggests the relationship is not by chance. However,beyond that rule, it doesn't seem like there are any other rules that would be meaningful enough to warrant spending money on our marketing campaign."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
