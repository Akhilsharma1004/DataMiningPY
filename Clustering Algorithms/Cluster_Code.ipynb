{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb7a91a",
   "metadata": {},
   "source": [
    "# Assignment 2 - Clustering\n",
    "\n",
    "Some basic code has been provided for you. You will need to make some small edits to complete the tasks in the instructions document. \n",
    "\n",
    "Feel free to write additional code as needed to support/illuminate your discussion in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e0789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import unique  # can also just use np.unique\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17635c33",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Load in the <code>salary_data.csv</code> dataset which has 50 data points and two dimensions (age, salary).\n",
    "\n",
    "Randomly generate a dataset with <b>50</b> data points using the <code>generate_random_data</code> method below.\n",
    "\n",
    "Run kmeans 10 times on each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0c0a02",
   "metadata": {},
   "source": [
    "#### Import Salary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = pd.read_csv('data/salary_data.csv')\n",
    "print(salary_data.shape)\n",
    "salary_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(salary_data.age, salary_data.income)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1e311",
   "metadata": {},
   "source": [
    "#### 1.1 Generate Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_data(n):\n",
    "    '''function to generate n random 2D data points stored in an (n, 2) dataframe'''\n",
    "    return pd.DataFrame({'x':np.random.rand(n), 'y':np.random.rand(n)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b090f10",
   "metadata": {},
   "source": [
    "Every time you run the <code>generate_random_data</code> function you will generate a new dataset so make sure you assign your dataset to a variable and don't write over that variable unless you're finished with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b92df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## EVERY TIME YOU RUN THIS YOU WILL GENERATE NEW DATA ##########\n",
    "\n",
    "# set n equal to the size of the dataset you want\n",
    "rand_data = generate_random_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a75a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rand_data.x, rand_data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99ecf23",
   "metadata": {},
   "source": [
    "#### 1.2 Run K-means\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c653138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function to run kmeans on your dataframe\n",
    "\n",
    "def run_kmeans(k, dataset, x_col='', y_col=''):\n",
    "    # let's make a copy of the dataframe so we can freely add columns\n",
    "    df = dataset.copy(deep=True) # just for our use case, don't do this as standard\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, init='random', n_init=1)\n",
    "    kmeans.fit(dataset)\n",
    "    cluster_labels = kmeans.fit_predict(dataset)\n",
    "    df[f'cluster_labels'] = cluster_labels\n",
    "    plt.scatter(df[x_col], df[y_col], c=kmeans.labels_.astype(float))\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_1_df = run_kmeans(3, salary_data, x_col='age', y_col='income')\n",
    "run_2_df = run_kmeans(3, salary_data, x_col='age', y_col='income')\n",
    "run_3_df = run_kmeans(3, salary_data, x_col='age', y_col='income')\n",
    "run_4_df = run_kmeans(3, salary_data, x_col='age', y_col='income')\n",
    "run_5_df = run_kmeans(3, salary_data, x_col='age', y_col='income')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446c078",
   "metadata": {},
   "source": [
    "### Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elbow_plot(dataset, x_col='', y_col='', min_k=1, max_k=10):\n",
    "    \n",
    "    # for what values of k do we want to run\n",
    "    k_range = range(min_k, max_k)\n",
    "\n",
    "    # calculate sum of squared error for each value of k\n",
    "    sse = [] # initialze empty list\n",
    "\n",
    "    for k in k_range:\n",
    "        km = KMeans(n_clusters=k) # set whatever other parameters you want here\n",
    "        km.fit(dataset)\n",
    "        sse.append(km.inertia_)\n",
    "\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Sum of Squared Error')\n",
    "    plt.plot(k_range, sse)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9cfea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_elbow_plot(salary_data, x_col='age', y_col='income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1085d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your own dataset of 30 points\n",
    "\n",
    "# generate an elbow plot for that data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297eb28",
   "metadata": {},
   "source": [
    "#### Normalize salary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(salary_data[['age']])\n",
    "salary_data['normalized_age'] = scaler.transform(salary_data[['age']])\n",
    "salary_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bec2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(salary_data[['income']])\n",
    "salary_data['normalized_income'] = scaler.transform(salary_data[['income']])\n",
    "salary_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=4) # or whatever number of k you want\n",
    "cluster_labels = km.fit_predict(salary_data[['normalized_age', 'normalized_income']])\n",
    "salary_data['normalized_cluster'] = cluster_labels\n",
    "plt.scatter(salary_data.normalized_age, salary_data.normalized_income, c=km.labels_.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13a6d3",
   "metadata": {},
   "source": [
    "# Task 2 \n",
    "\n",
    "We'll use Sklearn's <code>make_classification</code> method to generate a dataset. See documentation here: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html\n",
    "\n",
    "We aren't interested in the labels per-se, but it will generate some nicely clustered data for us to try out some algorithms on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53866dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "data_values, class_labels = make_classification(n_samples=2000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter plot for samples from each class\n",
    "for class_value in range(len(unique(class_labels))):\n",
    "    # get row indexes for samples with this class\n",
    "    row_ix = np.where(class_labels == class_value)\n",
    "    # create scatter of these samples\n",
    "    plt.scatter(data_values[row_ix, 0], data_values[row_ix, 1])\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a97b776",
   "metadata": {},
   "source": [
    "#### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9959b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=4) # set k to whatever makes sense for your data\n",
    "kmeans_model.fit(data_values)\n",
    "kmeans_clusters = kmeans_model.predict(data_values)\n",
    "\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in unique(kmeans_clusters):\n",
    "    # get row indexes for samples with this cluster\n",
    "    row_ix = np.where(kmeans_clusters == cluster)\n",
    "    # create scatter of these samples\n",
    "    plt.scatter(data_values[row_ix, 0], data_values[row_ix, 1])\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272fd8f",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dcfb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_model = DBSCAN(eps=0.30, min_samples=8)\n",
    "dbscan_clusters = dbscan_model.fit_predict(data_values)\n",
    "\n",
    "print(f'Found {len(unique(dbscan_clusters))} clusters')\n",
    "\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in unique(dbscan_clusters):\n",
    "    # get row indexes for samples with this cluster\n",
    "    row_ix = np.where(dbscan_clusters == cluster)\n",
    "    # create scatter of these samples\n",
    "    plt.scatter(data_values[row_ix, 0], data_values[row_ix, 1])\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b1dce",
   "metadata": {},
   "source": [
    "#### Some other algorithm...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
